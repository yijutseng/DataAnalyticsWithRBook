plot(x,y,col="blue",pch=19,cex=1)
text(x+0.05,y+0.05,labels=labelCar)
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=1)
# Make a cluster and cut it at the right height
distxy <- dist(dataFrame)
hcluster <- hclust(distxy)
dendro <- as.dendrogram(hcluster)
cutDendro <- cut(dendro,h=(hcluster$height[1]+0.00001) )
plot(cutDendro$lower[[23]],yaxt="n")
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
labelCar<-rownames(mtcars)[-1]
#install.packages("fields")
library(fields)
dataFrame <- data.frame(x=x,y=y)
rdistxy <- rdist(dataFrame) #Euclidean distance
diag(rdistxy) <- diag(rdistxy) + 1e5
# Find the index of the points with minimum distance
ind <- which(rdistxy == min(rdistxy),arr.ind=TRUE)
par(mfrow=c(1,2),mar=rep(1,4))
plot(x,y,col="blue",pch=19,cex=1)
text(x+0.05,y+0.05,labels=labelCar)
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=1)
# Make a cluster and cut it at the right height
distxy <- dist(dataFrame)
hcluster <- hclust(distxy)
dendro <- as.dendrogram(hcluster)
cutDendro <- cut(dendro,h=(hcluster$height[1]+0.00001) )
plot(cutDendro$lower[[23]],yaxt="n")
# Find the index of the points with minimum distance
ind3 <- which(rdistxy == rdistxy[order(rdistxy)][3],arr.ind=TRUE)
par(mfrow=c(1,1),mar=rep(0.2,4))
# Plot the points with the minimum overlayed
plot(x,y,col="blue",pch=19,cex=1)
text(x+0.05,y+0.05,labels=labelCar)
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=1)
points(x[ind3[1,]],y[ind3[1,]],col="red",pch=19,cex=1)
# Find the index of the points with minimum distance
ind3 <- which(rdistxy == rdistxy[order(rdistxy)][3],arr.ind=TRUE)
par(mfrow=c(1,3),mar=rep(0.2,4))
# Plot the points with the minimum overlayed
plot(x,y,col="blue",pch=19,cex=1)
text(x+0.05,y+0.05,labels=labelCar)
points(x[ind[1,]],y[ind[1,]],col="orange",pch=19,cex=1)
points(x[ind3[1,]],y[ind3[1,]],col="red",pch=19,cex=1)
# Make dendogram plots
distxy <- dist(dataFrame)
hcluster <- hclust(distxy)
dendro <- as.dendrogram(hcluster)
cutDendro <- cut(dendro,h=(hcluster$height[2]) )
plot(cutDendro$lower[[19]],yaxt="n")
plot(cutDendro$lower[[22]],yaxt="n")
mtcars.mxs<-as.matrix(mtcars)
d<-dist(mtcars.mxs) #預設為euclidean
head(d)
d<-dist(mtcars.mxs, method="manhattan") #計算manhattan距離
head(d)
par(mar=rep(2,4),mfrow=c(1,1))
hc<-hclust(dist(mtcars.mxs)) #可用method參數設定聚合方法，預設為complete
plot(hc)
par(mar=rep(2,4),mfrow=c(1,1))
hc<-hclust(dist(mtcars.mxs),method="average") #聚合方法為計算平均距離
plot(hc)
clusterCut <- cutree(hc, k=5) #分5群
sort(clusterCut)
ggplot()+geom_point(data=mtcars,
aes(x=hp,y=mpg,color=as.factor(clusterCut)))
clusterCut <- cutree(hc,h =4) #切在高度=4的地方（距離=4）
sort(clusterCut)
par(mar=rep(0.2,4),mfrow=c(1,1))
heatmap(mtcars.mxs)
distxy <- dist(mtcars.mxs)
hClustering <- hclust(distxy)
plot(hClustering)
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=labelCar)
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=labelCar)
cx <- c(-1,0.5,2.5)
cy <- c(2,0,-1)
points(cx,cy,col=c("red","orange","purple"),pch=3,cex=2,lwd=2)
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=labelCar)
cx <- c(-1,0.5,2.5)
cy <- c(2,0,-1)
points(cx,cy,col=cols1,pch=3,cex=2,lwd=2)
## Find the closest centroid
distTmp <- matrix(NA,nrow=3,ncol=length(x))
distTmp[1,] <- (x-cx[1])^2 + (y-cy[1])^2
distTmp[2,] <- (x-cx[2])^2 + (y-cy[2])^2
distTmp[3,] <- (x-cx[3])^2 + (y-cy[3])^2
newClust <- apply(distTmp,2,which.min)
points(x,y,pch=19,cex=2,col=cols1[newClust])
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=labelCar)
## Find the closest centroid
points(x,y,pch=19,cex=2,col=cols1[newClust])
newCx <- tapply(x,newClust,mean)
newCy <- tapply(y,newClust,mean)
points(newCx,newCy,col=cols1,pch=3,cex=2,lwd=2)
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=labelCar)
points(newCx,newCy,col=cols1,pch=3,cex=2,lwd=2)
## Iteration 2
distTmp <- matrix(NA,nrow=3,ncol=length(x))
distTmp[1,] <- (x-newCx[1])^2 + (y-newCy[1])^2
distTmp[2,] <- (x-newCx[2])^2 + (y-newCy[2])^2
distTmp[3,] <- (x-newCx[3])^2 + (y-newCy[3])^2
newClust2 <- apply(distTmp,2,which.min)
points(x,y,pch=19,cex=2,col=cols1[newClust2])
par(mar=rep(0.2,4))
plot(x,y,col="blue",pch=19,cex=2)
cols1 <- c("red","orange","purple")
text(x+0.05,y+0.05,labels=labelCar)
## Final centroids
finalCx <- tapply(x,newClust2,mean)
finalCy <- tapply(y,newClust2,mean)
points(finalCx,finalCy,col=cols1,pch=3,cex=2,lwd=2)
points(x,y,pch=19,cex=2,col=cols1[newClust2])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=3)
names(kmeansObj)
kmeansObj$cluster
par(mar=rep(0.2,4))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
set.seed(1234)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
kmeansObj <- kmeans(dataMatrix,centers=3)
par(mfrow=c(1,2), mar = c(2, 4, 0.1, 0.1))
image(t(dataMatrix)[,nrow(dataMatrix):1],yaxt="n")
image(t(dataMatrix)[,order(kmeansObj$cluster)],yaxt="n")
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=2)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:2,pch=3,cex=3,lwd=3)
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=3)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=4)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:4,pch=3,cex=3,lwd=3)
# Load the libraries
if (!require('arules')){
install.packages("arules");
library(arules) #for Apriori演算法
}
if (!require('datasets')){
install.packages("datasets");
library(datasets) #for Groceries data
}
data(Groceries) # Load the data set
Groceries@data@Dim #169 種商品，9835筆交易資料
knitr::include_graphics("figure/groceries.png")
# Get the rules
rules <- apriori(Groceries, # data= Groceries
parameter = list(supp = 0.001, conf = 0.8), #參數最低限度
control = list(verbose=F)) #不要顯示output
options(digits=2) # Only 2 digits
inspect(rules[1:5]) # Show the top 5 rules
rules<-sort(rules, by="confidence", decreasing=TRUE) #按照confidence排序
inspect(rules[1:5]) # Show the top 5 rules
rulesR<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.08),
appearance = list(default="lhs",rhs="whole milk"), #設定右邊一定要是牛奶
control = list(verbose=F)) #不要顯示output
rulesR<-sort(rulesR, decreasing=TRUE,by="confidence") #按照confidence排序
inspect(rulesR[1:5]) # Show the top 5 rules
rulesL<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="whole milk"), #設定左邊一定要是牛奶
control = list(verbose=F)) #不要顯示output
rulesL<-sort(rulesL, decreasing=TRUE,by="confidence") #按照confidence排序
inspect(rulesL[1:5]) # Show the top 5 rules
if (!require('arulesViz')){
install.packages("arulesViz");
library(arulesViz)
}
#Mac->http://planspace.org/2013/01/17/fix-r-tcltk-dependency-problem-on-mac/
plot(rules,method="graph",interactive=TRUE,shading=NA) #會跑一陣子
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=2)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:2,pch=3,cex=3,lwd=3)
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=3)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:3,pch=3,cex=3,lwd=3)
x<-scale(mtcars$hp[-1]);y<-scale(mtcars$mpg[-1])
dataFrame <- data.frame(x,y)
kmeansObj <- kmeans(dataFrame,centers=4)
par(mar=rep(0.2,4),mfrow=c(1,1))
plot(x,y,col=kmeansObj$cluster,pch=19,cex=2)
points(kmeansObj$centers,col=1:4,pch=3,cex=3,lwd=3)
# Load the libraries
if (!require('arules')){
install.packages("arules");
library(arules) #for Apriori演算法
}
if (!require('datasets')){
install.packages("datasets");
library(datasets) #for Groceries data
}
data(Groceries) # Load the data set
Groceries@data@Dim #169 種商品，9835筆交易資料
knitr::include_graphics("figure/groceries.png")
# Get the rules
rules <- apriori(Groceries, # data= Groceries
parameter = list(supp = 0.001, conf = 0.8), #參數最低限度
control = list(verbose=F)) #不要顯示output
options(digits=2) # Only 2 digits
inspect(rules[1:5]) # Show the top 5 rules
rules<-sort(rules, by="confidence", decreasing=TRUE) #按照confidence排序
inspect(rules[1:5]) # Show the top 5 rules
rulesR<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.08),
appearance = list(default="lhs",rhs="whole milk"), #設定右邊一定要是牛奶
control = list(verbose=F)) #不要顯示output
rulesR<-sort(rulesR, decreasing=TRUE,by="confidence") #按照confidence排序
inspect(rulesR[1:5]) # Show the top 5 rules
rulesL<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="whole milk"), #設定左邊一定要是牛奶
control = list(verbose=F)) #不要顯示output
rulesL<-sort(rulesL, decreasing=TRUE,by="confidence") #按照confidence排序
inspect(rulesL[1:5]) # Show the top 5 rules
knitr::include_graphics("figure/arulesViz.png")
knitr::include_graphics("figure/arulesVizBig.png")
knitr::include_graphics("figure/SupervisedLearning.png")
#讀入SportsAnalytics package
if (!require('SportsAnalytics')){
install.packages("SportsAnalytics")
library(SportsAnalytics)
}
#擷取2015-2016年球季球員資料
NBA1516<-fetch_NBAPlayerStatistics("15-16")
NBA1516<-NBA1516[complete.cases(NBA1516),]
sample(1:10,3) # 從1到10，隨機取三個數字
sample(1:nrow(NBA1516),nrow(NBA1516)/3) #從第一行到最後一行，隨機取1/3行數
NBA1516$Test<-F #新增一個參數紀錄分組
#隨機取1/3當Test set
NBA1516[sample(1:nrow(NBA1516),nrow(NBA1516)/3),]$Test<-T
# Training set : Test set球員數
c(sum(NBA1516$Test==F),sum(NBA1516$Test==T))
fit<-glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+
Position+ThreesAttempted+FreeThrowsAttempted,
data =NBA1516[NBA1516$Test==F,])
summary(fit)$coefficients
library(MASS)
##根據AIC，做逐步選擇, 預設倒退學習 direction = "backward"
##trace=FALSE: 不要顯示步驟
finalModel_B<-stepAIC(fit,direction = "backward",trace=FALSE)
summary(finalModel_B)$coefficients
##根據AIC，做逐步選擇, 往前學習 direction = "forward"
finalModel_F<-stepAIC(fit,direction = "forward",trace=FALSE)
summary(finalModel_F)$coefficients
##根據AIC，做逐步選擇, 雙向學習 direction = "both"
finalModel_Both<-stepAIC(fit,direction = "both",trace=FALSE)
summary(finalModel_Both)$coefficients
predictPoint<-predict(finalModel_Both, #Test==T, test data
newdata = NBA1516[NBA1516$Test==T,])
cor(x=predictPoint,y=NBA1516[NBA1516$Test==T,]$TotalPoints) #相關係數
plot(x=predictPoint,y=NBA1516[NBA1516$Test==T,]$TotalPoints)
mydata <- read.csv("https://raw.githubusercontent.com/CGUIM-BigDataAnalysis/BigDataCGUIM/master/binary.csv")
mydata$admit <- factor(mydata$admit) # 類別變項要轉為factor
mydata$rank <- factor(mydata$rank) # 類別變項要轉為factor
mydata$Test<-F #新增一個參數紀錄分組
mydata[sample(1:nrow(mydata),nrow(mydata)/3),]$Test<-T #隨機取1/3當Test set
c(sum(mydata$Test==F),sum(mydata$Test==T)) # Training set : Test set學生數
#修改一下factor的level: 改成Level 1為錄取，2為不錄取-->Level 1 要放正面答案
mydata$admit<-factor(mydata$admit,levels=c(1,0))
# GRE:某考試成績, GPA:在校平均成績, rank:學校聲望
mylogit <- glm(admit ~ gre + gpa + rank,
data = mydata[mydata$Test==F,], family = "binomial")
finalFit<-stepAIC(mylogit,direction = "both",trace=FALSE) # 雙向逐步選擇模型
summary(finalFit)
AdmitProb<-predict(finalFit, # 用Training set做的模型
newdata = mydata[mydata$Test==T,], #Test==T, test data
type="response") #結果為每個人被錄取的機率
head(AdmitProb)
table(AdmitProb<0.5,mydata[mydata$Test==T,]$admit) # row,column
knitr::include_graphics("figure/Cond.png")
knitr::include_graphics("figure/para.png")
table(AdmitProb<0.5,mydata[mydata$Test==T,]$admit) # row,column
knitr::include_graphics("figure/para.png")
AdmitProb<-predict(finalFit,
newdata = mydata[mydata$Test==T,], #Test==T, test data
type="response") #結果為每個人『不』被錄取的機率
AdmitAns<-factor(ifelse(AdmitProb<0.5,1,0),levels=c(1,0))
str(AdmitAns)
library(caret) # install.packages("caret") #計算參數的packages
sensitivity(AdmitAns,mydata[mydata$Test==T,]$admit)
specificity(AdmitAns,mydata[mydata$Test==T,]$admit)
posPredValue(AdmitAns,mydata[mydata$Test==T,]$admit)
negPredValue(AdmitAns,mydata[mydata$Test==T,]$admit)
if (!require('rpart')){
install.packages("rpart"); library(rpart)
}
DT<-rpart(Position~Blocks+TotalRebounds+ThreesMade+Assists+Steals,
data=NBA1516[NBA1516$Test==F,]) #訓練組 Training set
#控球後衛（PG）、得分後衛（SG）、小前鋒（SF）、大前鋒（PF）和中鋒（C）
DT
if (!require('rpart.plot')){
install.packages("rpart.plot");
library(rpart.plot)
}
prp(DT)	# 把決策樹畫出來
prp(DT)
posPred<-predict(DT,newdata= NBA1516[NBA1516$Test==T,]) #Test==T, test data
# 預設為class probabilities, type = "prob"
head(posPred)
result<-cbind(round(posPred,digits = 2),
NBA1516[NBA1516$Test==T,]$Name,
as.character(NBA1516[NBA1516$Test==T,]$Position))
head(result)
posPredC<-predict(DT,newdata= NBA1516[NBA1516$Test==T,],type = "class")
# type = "class" 直接預測類別
head(posPredC)
resultC<-cbind(as.character(posPredC),NBA1516[NBA1516$Test==T,]$Name,
as.character(NBA1516[NBA1516$Test==T,]$Position))
head(resultC)
#install.packages("mlbench") # 此package內有很多dataset可練習
library(mlbench)
data(Sonar)
str(Sonar) #看一下資料型別，有沒有缺值，類別變項是不是factor
library(ggplot2);library(reshape2) #install.packages(c("ggplot2","reshape2"))
Sonar.m<-melt(Sonar,id.vars = c("Class"))
ggplot(Sonar.m)+geom_boxplot(aes(x=Class,y=value))+
facet_wrap(~variable, nrow=5,scales = "free_y") #圖片太小了
Sonar$Test<-F #新增一個參數紀錄分組
#隨機取1/3當Test set
Sonar[sample(1:nrow(Sonar),nrow(Sonar)/3),]$Test<-T
# 看一下 Training set : Test set 案例數
c(sum(Sonar$Test==F),sum(Sonar$Test==T))
fit<-glm(Class~., Sonar[Sonar$Test==F,],family="binomial")
finalFit<-stepAIC(fit,direction = "both",trace = F)
summary(finalFit)$coefficients
MinePred<-predict(finalFit,newdata = Sonar[Sonar$Test==T,])
MineAns<-ifelse(MinePred<0.5,"M","R") #<0.5: Level 1
MineAns<-factor(MineAns,levels = c("M","R"))
MineAns
library(caret) # install.packages("caret") #計算參數的packages
sensitivity(MineAns,Sonar[Sonar$Test==T,]$Class)
specificity(MineAns,Sonar[Sonar$Test==T,]$Class)
posPredValue(MineAns,Sonar[Sonar$Test==T,]$Class)
negPredValue(MineAns,Sonar[Sonar$Test==T,]$Class)
mtcars.mxs<-as.matrix(mtcars)
d<-dist(mtcars.mxs) #預設為euclidean
head(d)
bookdown::render_book()
bookdown:::serve_book()
bookdown::render_book()
bookdown:::serve_book()
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
bookdown:::serve_book()
blogdown:::serve_site()
install.packages("bookdown")
install.packages("bookdown")
blogdown:::serve_site()
blogdown:::serve_site()
bookdown::serve_book()
sessionInfo()
sessionInfo()
pkg<-c('ggplot2', 'dplyr','lubridate','bit64','bookdown','knitr','rmarkdown','RCurl','data.table','stringr','reshape2','SportsAnalytics','readr','readxl','jsonlite','XML','Rfacebook','rvest','rgdal','rgeos','maptools','ggmap','choroplethr','choroplethrMaps','WDI','treemapify','shiny','plotly','ggvis','googleVis','rpart',
'rpart.plot','fields','arules','datasets','arulesViz','MASS','caret','purrr','treemap')
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
ipak(pkg)
session_history()
sessionInfo()
sessionInfo()
bookdown::serve_book()
install.packages('curl')
bookdown::serve_book()
library(curl)
bookdown::serve_book()
bookdown::serve_book()
library(curl)
bookdown::serve_book()
sessionInfo()
sessionInfo()
bookdown::serve_book()
install.packages("RCurl")
install.packages("RCurl")
bookdown::serve_book()
PetData<-jsonlite::fromJSON("http://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=f4a75ba9-7721-4363-884d-c3820b0b917c")
str(PetData)
install.packages("jsonlite")
install.packages("jsonlite")
PetData<-jsonlite::fromJSON("http://data.taipei/opendata/datalist/apiAccess?scope=resourceAquire&rid=f4a75ba9-7721-4363-884d-c3820b0b917c")
str(PetData)
bookdown::serve_book()
sessionInfo()
sessionInfo()
bookdown::serve_book()
sessionInfo()
library(curl)
install.packages(c("choroplethr", "data.table", "ggmap", "ggplot2", "knitr", "reshape2", "SportsAnalytics", "treemap", "treemapify"))
install.packages("knitr")
pkg<-c('ggplot2', 'dplyr','lubridate','bit64','bookdown','knitr','rmarkdown','RCurl','data.table','stringr','reshape2','SportsAnalytics','readr','readxl','jsonlite','XML','Rfacebook','rvest','rgdal','rgeos','maptools','ggmap','choroplethr','choroplethrMaps','WDI','treemapify','shiny','plotly','ggvis','googleVis','rpart',
'rpart.plot','fields','arules','datasets','arulesViz','MASS',
'caret','purrr','treemap','curl')
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
ipak(pkg)
pkg<-c('ggplot2', 'dplyr','lubridate','bit64','bookdown','knitr','rmarkdown','RCurl','data.table','stringr','reshape2','SportsAnalytics','readr','readxl','httr','jsonlite','XML','Rfacebook','rvest','rgdal','rgeos','maptools','ggmap','choroplethr','choroplethrMaps','WDI','treemapify','shiny','plotly','ggvis','googleVis','rpart',
'rpart.plot','fields','arules','datasets','arulesViz','MASS',
'caret','purrr','treemap','curl')
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
ipak(pkg)
bookdown::serve_book()
bookdown::serve_book()
bookdown::serve_book()
bookdown::serve_book()
bookdown::serve_book()
bookdown::serve_book()
bookdown::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
install.packages("bookdown")
library(ggmap)
register_google(key = "AIzaSyC7JRppSZtZuzpy9SdsVbpK5Nhf_oh2xl0")
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),
zoom = 7,
language = "zh-TW")
?get_googlemap
get_googlemap("waco, texas") %>% ggmap()
devtools::install_github("dkahle/ggmap")
devtools::install_github("dkahle/ggmap")
library(ggmap)
register_google(key = "AIzaSyC7JRppSZtZuzpy9SdsVbpK5Nhf_oh2xl0")
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),
zoom = 7,
language = "zh-TW")
library(ggmap)
register_google(key = "AIzaSyC7JRppSZtZuzpy9SdsVbpK5Nhf_oh2xl0")
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),
zoom = 7,
language = "zh-TW")
library(ggmap)
register_google(key = "AIzaSyC7JRppSZtZuzpy9SdsVbpK5Nhf_oh2xl0")
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),
zoom = 7,
language = "zh-TW")
library(SportsAnalytics)
NBA1516<-fetch_NBAPlayerStatistics("15-16") ## 讀入資料
library(ggmap)
register_google(key = "AIzaSyBD_nXDjGMYcJO9e_3SI_h3YZwhx0if680")
twmap <- get_googlemap(center = c(lon=120.58,lat=23.58),
zoom = 7,
language = "zh-TW")
data(continental_us_states)
library(ggmap)
register_google(key = "AIzaSyBD_nXDjGMYcJO9e_3SI_h3YZwhx0if680")
state_choropleth(df_pop_state,reference_map = TRUE,
zoom= continental_us_states) #把各州人口畫在地圖上
library(choroplethr)
data(continental_us_states)
library(ggmap)
register_google(key = "AIzaSyBD_nXDjGMYcJO9e_3SI_h3YZwhx0if680")
state_choropleth(df_pop_state,reference_map = TRUE,
zoom= continental_us_states) #把各州人口畫在地圖上
data(df_pop_state) #記載各州人口數的資料
state_choropleth(df_pop_state) #把各州人口畫在地圖上
data(continental_us_states)
library(ggmap)
register_google(key = "AIzaSyBD_nXDjGMYcJO9e_3SI_h3YZwhx0if680")
state_choropleth(df_pop_state,reference_map = TRUE,
zoom= continental_us_states) #把各州人口畫在地圖上
install.packages("mapproj")
bookdown:::serve_book()
?sensitivity
AdmitAns
mydata[mydata$Test==T,]$admit
AdmitAns
mydata[mydata$Test==T,]$admit
sensitivity(AdmitAns,mydata[mydata$Test==T,]$admit,positive = "1")
bookdown:::serve_book()
